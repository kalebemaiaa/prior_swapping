# -*- coding: utf-8 -*-
"""Exemplos finais.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cG6veBK5z9flJ7-Cjf0dDKniZpl_c03W
"""

from typing import Callable, overload, Literal
from torch import autograd, nn
from tqdm import tqdm

import matplotlib.pyplot as plt
import matplotlib.cm as cm
import seaborn as sns
import pandas as pd
import numpy as np
import kagglehub
import torch
import os

sns.set_theme()

# @title Download dataset
path = kagglehub.dataset_download("zakariaeyoussefi/song-year-prediction-msd")

complete_path = os.path.join(path, "YearPredictionMSD.csv")

# @title load data from dataset
df_yearMSD = pd.read_csv(complete_path)
columns_features = [c for c in df_yearMSD.columns if c != "Year"]
x_data = df_yearMSD[columns_features]
y_data = df_yearMSD["Year"]

# converte para tensor
X_np = x_data.values
X_np = (X_np - X_np.mean(axis=0)) / X_np.std(axis=0)
intercept = np.ones((X_np.shape[0], 1))
X_full = np.hstack([intercept, X_np])
X_hat = torch.tensor(X_full, dtype=torch.float64)
y_hat = torch.tensor(y_data.values, dtype=torch.float64)
y_hat = (y_hat - y_hat.mean()) / y_hat.std()

# X_hat = (X_hat - X_hat.mean(dim=0)) / X_hat.std(dim=0)
# y_hat = (y_hat - y_hat.mean()) / y_hat.std()

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
DTYPE = torch.float64

# Parâmetros
N = 3

mu = 20.0
b = np.sqrt(1/2)

theta_true = np.random.laplace(loc=mu, scale=b)
X = torch.normal(mean=theta_true, std=1.0, size=(N,))

print("Theta verdadeiro:", theta_true)

# @title Importance sampling

normal_padrao = Normal(0, 1)
laplace = Laplace(20, 1/2)
false_posterior = PosterioriFromX(X, normal_padrao)
real_posterior = PosterioriFromX(X, laplace)

estado_inicial = torch.as_tensor(2, dtype=torch.float64)
pesos_exemplo = []
for i in range(2, 4):
    sampler = Sampler(f_log_prob=false_posterior.log)
    amostras_false = sampler.get_samples("mh", estado_inicial, use_log_pdf=True, n_amostras = 10**i)

    sampler = Sampler(f_log_prob=real_posterior.log)
    amostras_real = sampler.get_samples("mh", estado_inicial, use_log_pdf=True, n_amostras = 10**i)
    # Calcular pesos de importância (Laplace / Normal)
    pesos = laplace.pdf(amostras_false) / normal_padrao.pdf(amostras_false)

    # Normalizar pesos para somarem 1
    pesos = pesos / pesos.sum()
    mu_is = torch.sum(amostras_false * pesos)
    pesos_exemplo.append(mu_is)

# --- Plotando ---
plt.close()
sns.set(style="whitegrid", font_scale=1.2)
fig, ax = plt.subplots(figsize=(10, 6))

# --- PDF da Normal padrão ---
lin_space = np.linspace(-5, 25, 400)
plot_normal = [normal_padrao.pdf(torch.tensor(i)).cpu() for i in lin_space]
ax.plot(lin_space, plot_normal, color="#1f77b4", lw=2, label="$\\pi_f(\\theta)\\sim N(0,1)$")

# --- PDF da Laplace ---
plot_laplace = [laplace.pdf(torch.tensor(i)).cpu() for i in lin_space]
ax.plot(lin_space, plot_laplace, color="#ff7f0e", lw=2, label="$\\pi(\\theta)\\sim Laplace(10,1)$")

# --- Posteriores ---
plt.hist(amostras_false.cpu(), bins=30, color="#d62728", alpha=0.5, label="$p_f(\\theta|x)$", density=True)
plt.hist(amostras_real.cpu(), bins=30, color="#2ca02c", alpha=0.5, label="$p(\\theta|x)$", density=True)

# --- Escolhe um colormap (tab10 tem boas cores distintas) ---
colors = cm.get_cmap("tab10", len(pesos_exemplo))

# --- Linhas das médias IS ---
for eidx, val in enumerate(pesos_exemplo):
    ax.axvline(
        val.cpu(),
        ymax=0.5,
        color=colors(eidx),            # <- cor muda conforme índice
        linestyle="--",
        lw=1.8,
        label=f"$\\hat{{\\mu}}_h^{{IS}} = {val:.2f}$, $T = 10^{eidx+2}$"
    )

# --- Ajustes visuais ---
ax.set_xlim(-5, 25)
ax.set_ylim(bottom=0)
ax.set_xlabel(r"$\theta$", fontsize=14)
ax.set_ylabel("Density", fontsize=14)
ax.set_title(f"Comparison of Priors and Posterior Distributions, $\\mu_h = {theta_true:.2f}$", fontsize=16, pad=15)
ax.legend(frameon=True, loc="upper left", fontsize=10)
ax.spines["top"].set_visible(False)
ax.spines["right"].set_visible(False)

plt.tight_layout()
plt.savefig("IS_method_example.png")
plt.show()

# @title Prior Swapping fechada
n = len(X)
p_f = Normal(n * X.mean()/(n + 1), (1/(n+1)) **0.5)
ps_real = lambda x: p_f.log(x) + laplace.log(x) - normal_padrao.log(x)

estado_inicial = torch.as_tensor(2, dtype=torch.float64)
pesos_exemplo_2 = []
for i in range(2, 4):
    sampler = Sampler(f_log_prob=ps_real)
    PS_samples = sampler.get_samples("mh", estado_inicial, use_log_pdf=True, n_amostras = 10**i)
    pesos_exemplo_2.append(PS_samples.mean())

plt.close()
sns.set(style="whitegrid", font_scale=1.2)

fig, ax = plt.subplots(figsize=(10, 6))

# --- PDF da Normal padrão ---
lin_space = np.linspace(-5, 25, 400)
plot_normal = [normal_padrao.pdf(torch.tensor(i)) for i in lin_space]
ax.plot(lin_space, plot_normal, color="#1f77b4", lw=2, label="$\\pi_f(\\theta)\\sim N(0,1)$")

# --- PDF da Laplace ---
plot_laplace = [laplace.pdf(torch.tensor(i)) for i in lin_space]
ax.plot(lin_space, plot_laplace, color="#ff7f0e", lw=2, label="$\\pi(\\theta)\\sim Laplace(10,1)$")

# --- Posteriores ---
plt.hist(amostras_false, bins=30, color="#d62728", alpha=0.5, label="$p_f(\\theta|x)$", density=True)
plt.hist(amostras_real, bins=30, color="#2ca02c", alpha=0.5, label="$p(\\theta|x)$", density=True)

# --- Escolhe um colormap (tab10 tem boas cores distintas) ---
colors = cm.get_cmap("tab10", len(pesos_exemplo_2))

# --- Linhas das médias IS ---
for eidx, val in enumerate(pesos_exemplo_2):
    ax.axvline(
        val,
        ymax=0.5,
        color=colors(eidx),            # <- cor muda conforme índice
        linestyle="--",
        lw=1.8,
        label=f"$\\hat{{\\mu}}_h^{{PS}} = {val:.2f}$, $T = 10^{eidx+2}$"
    )

# --- Ajustes visuais ---
ax.set_xlim(-5, 25)
ax.set_ylim(bottom=0)
ax.set_xlabel(r"$\theta$", fontsize=14)
ax.set_ylabel("Density", fontsize=14)
ax.set_title(f"Comparison of Priors and Posterior Distributions, $\\mu_h = {theta_true:.2f}$", fontsize=16, pad=15)
ax.legend(frameon=True, loc="upper left", fontsize=10)
ax.spines["top"].set_visible(False)
ax.spines["right"].set_visible(False)

plt.tight_layout()
plt.savefig("PS_method.png")
plt.show()

"""$$
p_s^\alpha(\theta)
    \propto
    \frac
        {\tilde{p}_f^\alpha(\theta)\pi(\theta)}
        {\pi_f(\theta)}
$$

$$
    \tilde{p}_f^\alpha(\theta)
        \propto
        \pi_f(\theta) \prod_{j=1}^k p(\alpha_j|\theta)^{\frac{n}{k}}
$$
"""

# @title Otimizador


"""# Código artigo

No exemplo, vamos usar um conjunto de dados $ N \text{ com dimensões } 500.000 \times 91 $.
Vamos modelar como $ x_i = [N_{i;1}, N_{i;2}, \dots, N_{i;90}] $ sendo uma amostra e $ y_i = N_{i;91} $ como a saída do modelo para essa amostra.

Com isso, podemos escrever:

$$
X = \begin{bmatrix}
1 & N_{1;1} & N_{1;2} & \dots & N_{1;90} \\
1 & N_{2;1} & N_{2;2} & \dots & N_{2;90} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & N_{500000;1} & N_{500000;2} & \dots & N_{500000;90}
\end{bmatrix},
y = \begin{bmatrix}
N_{1;91} \\
N_{2;91} \\
\vdots \\
N{500000;91}
\end{bmatrix}
$$

note que já escrevemos X com o intercepto adicionado. Então nosso modelo é:

$$
    Y = X \cdot \theta + \epsilon\\
    \epsilon \sim \mathcal{N}(0,\sigma^2 I)\\
    \theta \sim \pi
$$

esse $\pi$ escolhido.

Por se tratar do caso conjugado, se a priori for $\mathcal{N}(m_0, \Lambda_0^{-1})$, podemos dizer que a posteriori tem forma $\mathcal{N}(\mu_f, \Sigma_f^{-1})$, com $\Sigma_f^{-1} = \Lambda_0 +\frac{1}{\sigma^2}X^TX$ e $\mu_f = \Sigma(\Lambda_0m_0 + \frac{1}{\sigma^2}X^Ty)$. Então vamos amostrar $p(\theta|X)$ com essa forma.

No caso, vamos precisar calcular $p(\alpha_k|\theta)$. Em uma regressão linear, esse theta é o vetor de parâmetros, mas o que seria $\alpha_k$? Nesse caso, alpha é um pseudo-dado, substituimos a matriz $X = [x_1, x_2, \dots, x_n]$ por poucos pseudo dados $\alpha = [\alpha_1, \alpha_2, \dots, \alpha_k]$. O ponto é que, no caso de uma regressão, queremos computar algo do tipo $p(y|X,\theta)$, mas então teriamos $\alpha = [x_i, y_i]$

ou seja, no fim, para calcular $p(\alpha_k|\theta)$, teremos em mente que
$$
p(\alpha_k|\theta)
\sim
\mathcal{N}(\alpha_k[0:-1]^T\theta, \sigma^2)
$$

podemos então calcular $p(\alpha_k|\theta)$ como $p(\alpha_k[-1]|\alpha_k[0:-1], \theta)$. Com isso, temos:

$$
log(p(\alpha_k|\theta))
=
-\frac{1}{2\sigma^2}(\alpha_k[-1] - \alpha_k[0:-1]^T\theta)^2 + log(2\pi\sigma^2)
$$
"""

# @title Função para amostrar de $p_f(\theta|x)$
def fake_posterior_samples(X, y, m0, Lambda0, sigma, n_samples):
    n, d = X.shape

    # Posterior precision
    Sigma_inv = Lambda0 + (1 / sigma**2) * (X.T @ X)

    # Posterior covariance
    Sigma = torch.linalg.inv(Sigma_inv)

    # Posterior mean
    mu = Sigma @ (Lambda0 @ m0 + (1 / sigma**2) * X.T @ y)

    # Dist multivariada
    dist = torch.distributions.MultivariateNormal(mu, Sigma)

    return dist.sample((n_samples,))

# @title Função para calcular $p(\alpha_k|\theta)$
def wrapper_log_alpha_as_data_scalar(sigma):
    sigma2 = sigma**2
    const = -0.5 * torch.log(2 * torch.pi * sigma2)

    def log_likelihood(alpha, theta):
        if alpha.ndim == 1:
            x = alpha[:-1]
            y = alpha[-1]
            resid = y - x.T @ theta
            return -0.5/sigma2 * resid**2 + const
        else:
            # alpha: (K, d+1)
            # theta: (B, d)

            x = alpha[:, :-1]              # (K, d)
            y = alpha[:, -1]               # (K,)

            # expandindo para broadcast
            # x: (1, K, d)
            # theta: (B, 1, d)
            xtheta = (theta.unsqueeze(1) * x.unsqueeze(0)).sum(-1)   # (B, K)

            resid = y.unsqueeze(0) - xtheta  # (B, K)

        return -0.5/sigma**2 * resid**2 + const # (B, K)

    return log_likelihood

mean0_priori = torch.zeros(X_hat.shape[1])
lambda0_priori = torch.eye(X_hat.shape[1])
fake_priori = MultivariateNormal(mean0_priori, lambda0_priori)
fake_posteriori = PosterioriNormal(X_hat, y_hat, fake_priori)

target_priori = Laplace(10, 1)

# usando sigma estimado via OLS
num_data_points, num_features = X_hat.shape
target_posteriori = PosterioriNormal(X_hat, y_hat, target_priori)

# TODO: gerar amostras falsas: samples da fake_posteriori
samples_fake_posteriori = fake_posterior_samples(X_hat, y_hat, m0=torch.zeros(X_hat.shape[1]), Lambda0=torch.eye(X_hat.shape[1]), sigma=1, n_samples=5)

# print(samples_fake_posteriori)
print(samples_fake_posteriori.shape)
print(samples_fake_posteriori.dtype)

alpha_num_samples = 1000
alpha_dim = num_features + 1 # no caso de uma regressão linear, 1 intercept + 90 features + 1 output
print(alpha_dim)

"""Temos então:
- **sample_fake_posteriori**: amostras ${\theta_t}_{t=1}^{T_f}$ geradas a partir de $p_f(\theta|x^n)$
- **N_dataset**: dimensão de dados sendo $n\times p$, representando uma linha do conjunto de dados incluindo o target y, N_dataset é $\mathbb{n}$
- **n_setps**: passos de treinamento, número de iterações para calculo
- **alpha_dim**: simplesmente a dimensão de uma linha do conjunto de dados, ou seja, se temos 90 features, esse valor sera **alpha_dim = 90 (features)+ 1 (intercepto) + 1 (valor predito)**.
"""

# INICIANDO OTIMIZADOR
theta_ols = torch.linalg.solve(X_hat.T@X_hat, X_hat.T@y_hat)
# XtX = X_hat.T @ X_hat
# print(torch.linalg.matrix_rank(XtX), XtX.shape)
resid = y_hat - X_hat @ theta_ols
sigma2_hat = (resid**2).sum() / (num_data_points - num_features)
sigma = torch.sqrt(sigma2_hat)
# print(sigma)
optimizer_test = Otimizador(log_false_priori=fake_priori.log, log_likelihood=wrapper_log_alpha_as_data_scalar(sigma), use_hutchinson=False, num_probes=32)
retorno_alpha_optimo = optimizer_test.find_alpha_star(
    samples=samples_fake_posteriori,
    N_dataset = num_data_points,
    n_steps = 10000,
    K_alpha_samples = alpha_num_samples,
    alpha_dim=alpha_dim,
    learning_rate=1e-5,
    batch_size=128,
    verbose=True)

print(optimizer_test.history["loss"])
plt.plot(optimizer_test.history["loss"])
plt.xlabel("Iteração")
plt.ylabel("Loss")
plt.title("Evolução do Score Matching Loss")
plt.grid(True)
plt.show()

df = pd.DataFrame(retorno_alpha_optimo.cpu(), columns=[f"alpha_{i}" for i in range(retorno_alpha_optimo.shape[1])])

# Salva em CSV
df.to_csv("alpha_star.csv", index=False)

print(retorno_alpha_optimo)
print(retorno_alpha_optimo.shape)

# priori laplace multivariada:
def wrapper_log_laplace(loc=0.0, scale=1.0):
    loc = torch.as_tensor(loc)
    scale = torch.as_tensor(scale)

    def log_laplace_prior(theta):
        diff = torch.abs(theta - loc).sum(dim=-1)
        d = theta.shape[-1]
        return -d * torch.log(2 * scale) - diff / scale

    return log_laplace_prior


# uma vez que temos o alpha optimal, definimos a densidade
def wrapper_p_f_alpha(priori_fake_log, log_lik_alpha, alpha, n, K):
    def log_p_f_alpha(theta):
        log_prior = priori_fake_log(theta)  # log π_f(θ)
        log_liks = torch.stack([log_lik_alpha(alpha_i, theta) for alpha_i in alpha])
        return log_prior + (n / K) * log_liks.sum(dim=0)
    return log_p_f_alpha

# Essa é a p_f(\theta|x)
resid = y_hat - X_hat @ theta_ols
sigma2_hat = (resid**2).sum() / (num_data_points - num_features)
sigma = torch.sqrt(sigma2_hat)
log_likelihood_alpha = wrapper_log_alpha_as_data_scalar(sigma)

# prioris fake e target
priori_fake = MultivariateNormal(torch.zeros(X_hat.shape[1]), torch.eye(X_hat.shape[1]))
priori_target = wrapper_log_laplace(0, 1)

# Essa então seria a versão final de p_f^\alpha*(\theta)
posteriori_false_estimation = wrapper_p_f_alpha(priori_fake.log,
                                                log_likelihood_alpha,
                                                retorno_alpha_optimo.to(dtype=DTYPE),
                                                num_data_points,
                                                alpha_num_samples)

# Temos entao p_s prop_to p_f^\alpha . priori(\trheta)/priori_fake9\theta)
def wrapper_swap_parametric(priori_target_log, priori_fake_log, log_p_f_alpha):
    def log_p_s(theta):
        return log_p_f_alpha(theta) + priori_target_log(theta) - priori_fake_log(theta)
    return log_p_s

# TODO: amostrar a partir dessa distribuição usando o sampler
sampler = Sampler(f_log_prob = wrapper_swap_parametric(priori_target, priori_fake.log, posteriori_false_estimation))
amostras_finais_ps_v1 = sampler.get_samples("mh", torch.zeros(X_hat.shape[1]), n_amostras=100, use_log_pdf=True)

amostras_finais_ps_v1.cpu().numpy()

"""# código emulação

"""

media_exemplo = torch.as_tensor(7.83, dtype=DTYPE, device=DEVICE)
sigma_exemplo = torch.as_tensor(3, dtype=DTYPE, device=DEVICE)
dados = torch.normal(media_exemplo, sigma_exemplo, (10000,))
dados

def likelihood_log_normal(alpha, theta, sigma=3):
    sigma2 = torch.as_tensor(sigma**2, device= DEVICE, dtype=DTYPE)

    # alpha: (K, 1)
    # theta: (T, 1)

    # adiciona dimensão para broadcast
    theta_exp = theta.unsqueeze(1)     # (T, 1, 1)
    alpha_exp = alpha.unsqueeze(0)     # (1, K, 1)

    resid = theta_exp - alpha_exp      # (T, K, 1)

    log_norm = -0.5 * torch.log(2 * np.pi * sigma2)
    log_lik  = log_norm - 0.5 * (resid**2).squeeze(-1) / sigma2

    return log_lik   # (T, K)


priori_target = Laplace(10, 1)
priori_fake = Normal(0, 1)

posteriori_target = PosterioriFromX(dados, priori_target, sigma_x = 3)
posteriori_fake = PosterioriFromX(dados, priori_fake, sigma_x = 3)

sampler_fake_posteriori = Sampler(f_log_prob=posteriori_fake.log)
samples_fake_posteriori = sampler_fake_posteriori.get_samples("mh", torch.zeros(1), n_amostras=10000, use_log_pdf=True)
sampler_fake_posteriori.plot_cadeia(samples_fake_posteriori)

optimizer_test = Otimizador(log_false_priori=priori_fake.log, log_likelihood=likelihood_log_normal, use_hutchinson=True, num_probes=32)
retorno_alpha_optimo = optimizer_test.find_alpha_star(
    samples=samples_fake_posteriori,
    N_dataset = len(dados),
    n_steps = 1000,
    K_alpha_samples = 100,
    alpha_dim=1,
    learning_rate=1e-5,
    batch_size=128,
    verbose=True)

# uma vez que temos o alpha optimal, definimos a densidade
def wrapper_p_f_alpha(priori_fake_log, log_lik_alpha, alpha, n, K):
    def log_p_f_alpha(theta):
        log_prior = priori_fake_log(theta)  # log π_f(θ)
        log_liks = torch.stack([log_lik_alpha(alpha_i, theta) for alpha_i in alpha])
        return log_prior + (n / K) * log_liks.sum(dim=0)
    return log_p_f_alpha

# Essa é a p_f(\theta|x)
# likelihood_log_normal(..

# Essa então seria a versão final de p_f^\alpha*(\theta)
posteriori_false_estimation = wrapper_p_f_alpha(priori_fake.log,
                                                likelihood_log_normal,
                                                retorno_alpha_optimo.to(dtype=DTYPE),
                                                len(dados),
                                                100)

# Temos entao p_s prop_to p_f^\alpha . priori(\trheta)/priori_fake9\theta)
def wrapper_swap_parametric(priori_target_log, priori_fake_log, log_p_f_alpha):
    def log_p_s(theta):
        return log_p_f_alpha(theta) + priori_target_log(theta) - priori_fake_log(theta)
    return log_p_s

# TODO: amostrar a partir dessa distribuição usando o sampler
sampler = Sampler(f_log_prob = wrapper_swap_parametric(priori_target.log, priori_fake.log, posteriori_false_estimation))
amostras_finais_ps_v1 = sampler.get_samples("mh", torch.zeros(1), n_amostras=1000, use_log_pdf=True)

print(amostras_finais_ps_v1)

# TODO: receber uma função kernel
# TODO: receber uma função de probabilidade paramétrica -> aquela otimizada com alpha
# TODO: receber samples falsos
# TODO: receber (parametro) largura de banda do kernel

# def semi_parametric(
#         self,
#         theta: torch.Tensor,
#         samples: torch.Tensor,
#         posterior_false: Callable, # essa função retorna p_f^a
#         posterior_true: Callable, #
#         bandwidth: float,
#         kernel_func: Callable|None = None
#     ) -> tuple[torch.Tensor, torch.Tensor]:
#         """Retorna a posteriori semi parametrica e o peso correspondente ao theta input"""
#         p_s_true = posterior_true(theta)

#         # se nao passar uma kernel_func, vamos usar a normal padrao
#         if kernel_func is None:
#             kernel_func = lambda x: torch.exp(-0.5 * (x**2)) / np.sqrt(2 * np.pi)

#         _, d = theta.shape

#         # calculando kenrel
#         diff = theta.unsqueeze(1) - samples.unsqueeze(1)
#         distances = torch.norm(diff, dim=1) / bandwidth
#         K_vals = kernel_func(distances)

#         # posteriores
#         epsilon = 1e-12
#         p_amostras: torch.Tensor = posterior_false(samples)
#         p_amostras = p_amostras.clamp_min(epsilon)
#         p_theta: torch.Tensor = posterior_false(theta)


#         correction = (K_vals * (p_theta.unsqueeze(1) / p_amostras.unsqueeze(0))).mean(dim=1)
#         correction = correction / (bandwidth ** d)

#         p_s = posterior_true(theta)
#         ps_semiparametric = p_s * correction

#         return ps_semiparametric, correction


class semiParametric:
    def __init__():
        pass

    def __normal_kernel(self):
        # TODO: se o kernel não for passado, usar a normal kernel
        # exp(-(x^2)/2)
        pass

    def density(theta, samples):
        normas = (samples - theta) / b
        # p_s_alpha é
        p_s_alpha(theta) + mean([funcao_kernel(norma) / samples[i] for i, norma in enumerate(normas)])

def function_sempi_parametric_postrior(theta)

def kde_log_density(theta, samples, bandwidth):
    """
    KDE gaussiana no log-space.
    theta: shape (D,)
    samples: shape (T, D)
    """
    D = theta.shape[-1]
    diffs = (samples - theta) / bandwidth   # shape (T, D)
    sq = (diffs**2).sum(dim=1)              # shape (T,)

    # kernel gaussiano
    log_kernels = -0.5 * sq - D * torch.log(bandwidth) - 0.5*D*torch.log(2*torch.pi)

    # log-mean-exp trick:
    return torch.logsumexp(log_kernels, dim=0) - torch.log(torch.tensor(samples.shape[0], dtype=theta.dtype))

def semi_parametric_swapping(
    log_p_f_alpha,       # log p_f^{α*}(θ)
    log_prior_target,    # log π_s(θ)
    samples,             # amostras da fake posterior
    bandwidth
):
    def log_p_s(theta):
        log_kde = kde_log_density(theta, samples, bandwidth)
        return log_p_f_alpha(theta) + log_prior_target(theta) - log_kde
    return log_p_s